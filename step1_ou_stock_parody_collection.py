import os
import feedparser
from datetime import datetime, timedelta
from anthropic import Anthropic
from dotenv import load_dotenv
from common_utils import get_gsheet
from difflib import SequenceMatcher
import json
import re
from pathlib import Path
import time

# .env íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì§€ì •í•˜ì—¬ ë¡œë“œ
env_path = Path('.') / '.env'
load_dotenv(dotenv_path=env_path, verbose=True)

# Claude AI API í‚¤
CLAUDE_API_KEY = os.getenv('CLAUDE_API_KEY')
if not CLAUDE_API_KEY:
    raise ValueError("CLAUDE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def parse_rawdata(file_path='asset/rawdata.txt'):
    """rawdata.txt íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì„¤ì •ê°’ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    config = {}
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            current_key = None
            values = []
            for line in f:
                line = line.strip()
                if not line:
                    continue
                if line.startswith('[') and line.endswith(']'):
                    if current_key and values:
                        config[current_key] = values[0] if len(values) == 1 else values
                    current_key = line[1:-1]
                    values = []
                elif current_key:
                    values.append(line)
            if current_key and values:
                config[current_key] = values[0] if len(values) == 1 else values
    except FileNotFoundError:
        print(f"ì„¤ì • íŒŒì¼({file_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    return config

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
SHEET_NAME = 'today_stock_parody'

def is_similar(str1, str2, threshold=0.8):
    """ë‘ ë¬¸ìì—´ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ì¤‘ë³µ ì—¬ë¶€ íŒë‹¨"""
    return SequenceMatcher(None, str1, str2).ratio() > threshold

def is_duplicate_news(news_item, existing_news):
    """ë‰´ìŠ¤ ì¤‘ë³µ ì—¬ë¶€ í™•ì¸"""
    for existing in existing_news:
        if is_similar(news_item['title'], existing['title']):
            return True
    return False

def fetch_news(rss_url, existing_news=None):
    """RSS í”¼ë“œì—ì„œ ì˜¤ëŠ˜ê³¼ ì–´ì œ ë‚ ì§œì˜ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    if existing_news is None:
        existing_news = []
    
    feed = feedparser.parse(rss_url)
    news_list = []
    today = datetime.now().date()
    yesterday = today - timedelta(days=1)
    
    for entry in feed.entries:
        published_date = None
        if hasattr(entry, 'published_parsed') and entry.published_parsed:
            # feedparserê°€ íŒŒì‹±í•œ 9-tuple ë‚ ì§œ êµ¬ì¡°ë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜
            published_date = datetime.fromtimestamp(time.mktime(entry.published_parsed)).date()
        
        # ì˜¤ëŠ˜ ë˜ëŠ” ì–´ì œ ë‰´ìŠ¤ê°€ ì•„ë‹ˆë©´ ê±´ë„ˆëœ€
        if published_date not in [today, yesterday]:
            continue
            
        title = entry.title
        summary = entry.summary if hasattr(entry, 'summary') else ''
        # ë‚ ì§œ í˜•ì‹ì€ YYYY-MM-DDë¡œ í†µì¼
        published = published_date.strftime('%Y-%m-%d')
        link = entry.link if hasattr(entry, 'link') else ''
        
        news_item = {
            'title': title,
            'summary': summary,
            'published': published,
            'link': link
        }
        
        # ì¤‘ë³µ ì²´í¬
        if not is_duplicate_news(news_item, existing_news):
            news_list.append(news_item)
            existing_news.append(news_item)
    
    return news_list

def rank_news_by_importance_with_claude(news_list):
    """Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ëª©ë¡ì„ ì¤‘ìš”ë„ì— ë”°ë¼ ìˆœìœ„ ë§¤ê¸°ê¸°"""
    client = Anthropic(api_key=CLAUDE_API_KEY)

    formatted_news = ""
    for i, news in enumerate(news_list):
        formatted_news += f"ID: {i}\\nì œëª©: {news['title']}\\n\\n"

    prompt = f"""ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ê¸ˆìœµ ë‰´ìŠ¤ íë ˆì´í„°ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ì˜¤ëŠ˜ê³¼ ì–´ì œ ìˆ˜ì§‘ëœ ì£¼ì‹/ì¦ê¶Œ ê´€ë ¨ ë‰´ìŠ¤ ëª©ë¡ì…ë‹ˆë‹¤. 
ê° ë‰´ìŠ¤ì˜ ì¤‘ìš”ë„ë¥¼ íŒë‹¨í•˜ì—¬, ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¶€í„° ìˆœì„œëŒ€ë¡œ ID ëª©ë¡ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

## ğŸŒŸ ì¤‘ìš”ë„ íŒë‹¨ ê¸°ì¤€ (ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ ì—„ê²©í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”)

### 1. ì‹œì¥ ì „ì²´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (ê±°ì‹œê²½ì œ, ì •ì±…)
- **í†µí™”ì •ì±… (ìµœìš°ì„ ):** í•œêµ­ì€í–‰, Fed ê¸ˆë¦¬, ì–‘ì ì™„í™”/ê¸´ì¶•
- **ê±°ì‹œê²½ì œ ì§€í‘œ:** í™˜ìœ¨ ê¸‰ë³€ë™, ìœ ê°€, ë¬¼ê°€ì§€ìˆ˜(CPI)
- **ì •ë¶€ ì •ì±…/ê·œì œ:** ì„¸ë²• ê°œì •, ë¶€ë™ì‚° ì •ì±…, ì‚°ì—… ê·œì œ

### 2. íŠ¹ì • ì‚°ì—… ë° ê¸°ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
- **í•µì‹¬ ì‚°ì—… ë™í–¥:**
  - **ë°˜ë„ì²´:** ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤ ì‹¤ì , HBM, AIì¹©, ë¯¸ì¤‘ê°ˆë“±
  - **ìë™ì°¨/2ì°¨ì „ì§€:** í˜„ëŒ€ì°¨/ê¸°ì•„ íŒë§¤ëŸ‰, ì „ê¸°ì°¨, ë°°í„°ë¦¬ ìˆ˜ì£¼
  - **ë°”ì´ì˜¤/ì‹ ì•½:** FDA ìŠ¹ì¸, ì„ìƒ ê²°ê³¼ ë°œí‘œ
  - **í”Œë«í¼/IT:** ë„¤ì´ë²„, ì¹´ì¹´ì˜¤ ê´€ë ¨ ê·œì œ, ì‹ ì‘ ë°œí‘œ
- **ì£¼ìš” ê¸°ì—… ì‹¤ì :** ë¶„ê¸° ì‹¤ì  ë°œí‘œ, ì–´ë‹ ì„œí”„ë¼ì´ì¦ˆ/ì‡¼í¬

### 3. íˆ¬ìì ë™í–¥
- **ì™¸êµ­ì¸/ê¸°ê´€:** ëŒ€ê·œëª¨ ìˆœë§¤ìˆ˜/ìˆœë§¤ë„, ì—°ê¸°ê¸ˆ ë™í–¥

## ğŸ“° ë‰´ìŠ¤ ëª©ë¡
{formatted_news}

## ğŸ’» ì¶œë ¥ í˜•ì‹
- ë‹¤ë¥¸ ì„¤ëª… ì—†ì´, ê°€ì¥ ì¤‘ìš”ë„ê°€ ë†’ì€ ë‰´ìŠ¤ë¶€í„° ìˆœì„œëŒ€ë¡œ IDë¥¼ **ì‰¼í‘œ(,)ë¡œë§Œ êµ¬ë¶„**í•˜ì—¬ í•œ ì¤„ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
- ì˜ˆì‹œ: 5,12,3,1,8,2,7,11,0,4

ê°€ì¥ ì¤‘ìš”í•œ ìˆœì„œëŒ€ë¡œ ID ëª©ë¡ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
"""

    response = client.messages.create(
        model="claude-3-5-sonnet-20240620",
        max_tokens=1000,
        temperature=0.1,
        messages=[{"role": "user", "content": prompt}]
    )
    
    response_text = response.content[0].text.strip()
    
    try:
        ranked_ids = [int(id_str.strip()) for id_str in response_text.split(',')]
        valid_ranked_ids = [id_val for id_val in ranked_ids if 0 <= id_val < len(news_list)]
        
        ranked_news = [news_list[i] for i in valid_ranked_ids]
        unranked_news_ids = set(range(len(news_list))) - set(valid_ranked_ids)
        unranked_news = [news_list[i] for i in unranked_news_ids]

        return ranked_news + unranked_news
    except ValueError:
        print("  ! AI ìˆœìœ„ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨. ì›ë˜ ìˆœì„œëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return news_list

def create_parody_with_claude(news_content, original_prompt, existing_titles, retry_context=None):
    """Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ íŒ¨ëŸ¬ë”” ìƒì„± (ì¤‘ë³µ ë°©ì§€ ë° ìë™ ë³µêµ¬ ê¸°ëŠ¥ í¬í•¨)"""
    client = Anthropic(api_key=CLAUDE_API_KEY)
    
    # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    if existing_titles:
        duplication_warning = (
            "\\n\\n## âœï¸ (ë§¤ìš° ì¤‘ìš”) ì¤‘ë³µ íŒ¨ëŸ¬ë”” ë°©ì§€\\n"
            "- ì•„ë˜ëŠ” ì´ë¯¸ ìƒì„±ëœ íŒ¨ëŸ¬ë”” ì œëª©ë“¤ì…ë‹ˆë‹¤.\\n"
            "- ì ˆëŒ€ë¡œ ì•„ë˜ ëª©ë¡ê³¼ ìœ ì‚¬í•œ ë‚´ìš©ì´ë‚˜ ìŠ¤íƒ€ì¼ì˜ `parody_title`ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.\\n"
            "- ì™„ì „íˆ ìƒˆë¡­ê³ , ì°½ì˜ì ì¸ ì œëª©ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.\\n\\n"
            "### ğŸ“œ ì´ë¯¸ ìƒì„±ëœ ì œëª© ëª©ë¡:\\n"
            f"- {'\\n- '.join(existing_titles)}"
        )
        original_prompt += duplication_warning

    messages = [{"role": "user", "content": original_prompt}]
    
    if retry_context:
        user_message = f"""ì´ì „ ì‘ë‹µì— ì˜¤ë¥˜ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
## ì´ì „ ì‘ë‹µ (ì˜ëª»ëœ ë¶€ë¶„)
{retry_context['malformed_json']}
## ë°œìƒí•œ ì˜¤ë¥˜
{retry_context['error_message']}
ìœ„ ì˜¤ë¥˜ë¥¼ ì°¸ê³ í•˜ì—¬, ìœ íš¨í•œ JSON í˜•ì‹ì— ë§ì¶° ìˆ˜ì •ëœ ì‘ë‹µì„ ```json ... ``` ì½”ë“œ ë¸”ë¡ ì•ˆì— ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
        messages.append({"role": "assistant", "content": retry_context['malformed_json']})
        messages.append({"role": "user", "content": user_message})

    response = client.messages.create(
        model="claude-3-5-sonnet-20240620",
        max_tokens=2000,
        temperature=0.7,
        messages=messages
    )
    
    return response.content

def save_to_gsheet(parody_data_list):
    """íŒ¨ëŸ¬ë”” ë°ì´í„°ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ (ì‹œíŠ¸ ì´ˆê¸°í™” í›„ ì €ì¥)"""
    sheet = get_gsheet(SHEET_NAME)
    
    # ì‹œíŠ¸ ì´ˆê¸°í™”
    sheet.clear()
    
    # í—¤ë” ì¶”ê°€
    headers = [
        'date', 'original_title', 'parody_title', 'setup', 
        'punchline', 'humor_lesson', 'disclaimer', 'source_url'
    ]
    sheet.append_row(headers)
    
    # ë°ì´í„° ì¶”ê°€
    for parody_data in parody_data_list:
        row = [
            parody_data.get('date', ''),
            parody_data.get('original_title', ''),
            parody_data.get('parody_title', ''),
            parody_data.get('setup', ''),
            parody_data.get('punchline', ''),
            parody_data.get('humor_lesson', ''),
            parody_data.get('disclaimer', ''),
            parody_data.get('source_url', '')
        ]
        sheet.append_row(row)

def main():
    print("[1/5] ë‰´ìŠ¤ ì†ŒìŠ¤ë³„ ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ë‰´ìŠ¤ ì„ ë³„ ì¤‘...")
    
    # ì„¤ì • íŒŒì¼ ë¡œë“œ
    raw_config = parse_rawdata()
    if not raw_config:
        print("[ì˜¤ë¥˜] ì„¤ì • íŒŒì¼(asset/rawdata.txt)ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # RSS í”¼ë“œ URL ì„¤ì •
    rss_urls = raw_config.get('RSS_URL ì§€ì •', [])
    if isinstance(rss_urls, str): # ê°’ì´ í•˜ë‚˜ì¼ ê²½ìš° ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ
        rss_urls = [rss_urls]

    if not rss_urls:
        print("[ì˜¤ë¥˜] asset/rawdata.txt íŒŒì¼ì—ì„œ 'RSS_URL ì§€ì •'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    RSS_FEEDS = {}
    for url in rss_urls:
        if 'mk.co.kr' in url:
            RSS_FEEDS["ë§¤ì¼ê²½ì œ_ì¦ê¶Œ"] = url
        elif 'yna.co.kr' in url:
            RSS_FEEDS["ì—°í•©ë‰´ìŠ¤_ì¦ê¶Œ"] = url

    # ìµœì¢…ì ìœ¼ë¡œ ì„ íƒë  ë‰´ìŠ¤ ëª©ë¡
    top_news = []
    # ì „ì²´ ì†ŒìŠ¤ì—ì„œ ì¤‘ë³µì„ í™•ì¸í•˜ê¸° ìœ„í•œ ë‰´ìŠ¤ ì œëª© ì§‘í•©
    collected_titles = set()
    # ê° ì†ŒìŠ¤ë³„ë¡œ ìˆœìœ„ê°€ ë§¤ê²¨ì§„ ë‰´ìŠ¤ í›„ë³´êµ°
    source_candidates = {}

    # 1. ê° ì†ŒìŠ¤ë³„ë¡œ ë‰´ìŠ¤ í›„ë³´êµ° ìƒì„±
    for source, url in RSS_FEEDS.items():
        print(f"\\n  -> '{source}' í›„ë³´êµ° ìƒì„± ì¤‘...")
        
        # ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ì´ì „ ë‹¨ê³„ëŠ” ì—†ìœ¼ë¯€ë¡œ, ì†ŒìŠ¤ ë‚´ ì¤‘ë³µë§Œ ì²´í¬)
        news_from_source = fetch_news(url)
        
        if not news_from_source:
            print("    - ì˜¤ëŠ˜/ì–´ì œ ë‰´ìŠ¤ê°€ ì—†ì–´ í›„ë³´êµ°ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue
            
        print(f"    - ì˜¤ëŠ˜/ì–´ì œ ë‰´ìŠ¤ {len(news_from_source)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ.")
        
        print("    - AIë¥¼ í†µí•´ ì¤‘ìš”ë„ ìˆœìœ„ ì„ ì • ì¤‘...")
        try:
            # í›„ë³´êµ°ì„ ë„‰ë„‰í•˜ê²Œ 10ê°œë¡œ ì„¤ì •
            ranked_news = rank_news_by_importance_with_claude(news_from_source)
            source_candidates[source] = ranked_news
            print(f"    - '{source}' í›„ë³´êµ° {len(ranked_news)}ê°œ ìƒì„± ì™„ë£Œ.")
        except Exception as e:
            print(f"      - AI ìˆœìœ„ ì„ ì • ì‹¤íŒ¨: {e}")
            source_candidates[source] = news_from_source # ì‹¤íŒ¨ ì‹œ ì›ë˜ ìˆœì„œëŒ€ë¡œ

    # 2. ì†ŒìŠ¤ë³„ í›„ë³´êµ°ì—ì„œ ì¤‘ë³µì„ í”¼í•´ ìµœì¢… ë‰´ìŠ¤ 20ê°œ ì„ ë³„ (êµì°¨ ë°©ì‹)
    print("\\n[2/5] ìµœì¢… ë‰´ìŠ¤ 20ê°œ ì„ ë³„ ì¤‘ (ë§¤ê²½/ì—°í•© êµì°¨, ì¤‘ë³µ ì œê±°)...")
    
    mk_candidates = source_candidates.get("ë§¤ì¼ê²½ì œ_ì¦ê¶Œ", [])
    yn_candidates = source_candidates.get("ì—°í•©ë‰´ìŠ¤_ì¦ê¶Œ", [])
    
    mk_idx, yn_idx = 0, 0

    # 20ê°œê°€ ì±„ì›Œì§€ê±°ë‚˜, ë‘ í›„ë³´êµ° ëª¨ë‘ ì†Œì§„ë  ë•Œê¹Œì§€ ë°˜ë³µ
    while len(top_news) < 20 and (mk_idx < len(mk_candidates) or yn_idx < len(yn_candidates)):
        
        # ë§¤ê²½ í„´ (top_newsê°€ 20ê°œ ë¯¸ë§Œì¼ ë•Œ)
        if len(top_news) < 20 and mk_idx < len(mk_candidates):
            while mk_idx < len(mk_candidates):
                candidate = mk_candidates[mk_idx]
                is_new = not any(is_similar(candidate['title'], existing['title']) for existing in top_news)
                mk_idx += 1
                if is_new:
                    top_news.append(candidate)
                    break

        # ì—°í•© í„´ (top_newsê°€ 20ê°œ ë¯¸ë§Œì¼ ë•Œ)
        if len(top_news) < 20 and yn_idx < len(yn_candidates):
            while yn_idx < len(yn_candidates):
                candidate = yn_candidates[yn_idx]
                is_new = not any(is_similar(candidate['title'], existing['title']) for existing in top_news)
                yn_idx += 1
                if is_new:
                    top_news.append(candidate)
                    break
    
    if not top_news:
        print("\\n[ì˜¤ë¥˜] ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print(f"\\n[2.5/5] ì´ {len(top_news)}ê°œ ê³ ìœ  ë‰´ìŠ¤ ì„ ë³„ ì™„ë£Œ! íŒ¨ëŸ¬ë”” ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    print(f"\\n[3/5] ì¤‘ìš”ë„ ìƒìœ„ {len(top_news)}ê°œ ë‰´ìŠ¤ë¡œ íŒ¨ëŸ¬ë”” ìƒì„± ì¤‘...")
    parody_data_list = []

    today_str = datetime.now().strftime('%Y-%m-%d')
    existing_parody_titles = [] # ìƒì„±ëœ íŒ¨ëŸ¬ë”” ì œëª©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    for i, news in enumerate(top_news):
        news_content = f"ì œëª©: {news['title']}\\në‚´ìš©: {news['summary']}\\në§í¬: {news['link']}"
        
        # í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ë  ë³€ìˆ˜ë“¤ì„ ë¯¸ë¦¬ ì¤€ë¹„í•˜ì—¬ f-string ì˜¤ë¥˜ ë°©ì§€
        current_date = datetime.now().strftime('%Y-%m-%d')
        original_title_safe = news['title'].replace('"', "'")
        news_link = news['link']

        parody_prompt = f"""ë‹¹ì‹ ì€ ìœ ë¨¸ ê°ê°ì´ ë›°ì–´ë‚œ ê¸ˆìœµ ì „ë¬¸ê°€ì´ì ì‹œë‚˜ë¦¬ì˜¤ ì‘ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì£¼ì‹ ì‹œì¥ì˜ ìƒí™©ì„ ì¬ì¹˜ìˆê²Œ í’ìí•˜ëŠ” ì§§ì€ íŒ¨ëŸ¬ë””ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.

## ğŸ“° ë¶„ì„í•  ë‰´ìŠ¤ ì›ë¬¸
- **ì œëª©:** {news['title']}
- **ìš”ì•½:** {news['summary']}

## ğŸ“ íŒ¨ëŸ¬ë”” ìƒì„± ê°€ì´ë“œë¼ì¸
1.  **íŒ¨ëŸ¬ë”” ì œëª© (parody_title):**
    - **(ì¤‘ìš”) 15~20ì ë‚´ì™¸ë¡œ ë§¤ìš° ì§§ê³  ì»´íŒ©íŠ¸í•˜ê²Œ** ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    - ë‰´ìŠ¤ ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì••ì¶•í•˜ë©´ì„œë„, ì›ƒìŒì„ ìœ ë°œí•˜ëŠ” ë°˜ì „ì´ë‚˜ ê³¼ì¥ì„ ë‹´ì•„ì£¼ì„¸ìš”.
    - ì˜ˆì‹œ: "ì‚¼ì „, HBM í…ŒìŠ¤íŠ¸ í†µê³¼? AIëŠ” ì•ˆë„ì˜ í•œìˆ¨"
2.  **ìƒí™© ì„¤ì • (setup):**
    - **(ì¤‘ìš”) 35ì ë‚´ì™¸ì˜ ì´ˆë‹¨ë¬¸ìœ¼ë¡œ** ë°°ê²½ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    - ë‰´ìŠ¤ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ìœ ë¨¸ë¥¼ ìœ„í•œ ë¬´ëŒ€ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
3.  **ë°˜ì „/ì›ƒìŒ í¬ì¸íŠ¸ (punchline):**
    - **(ì¤‘ìš”) 35ì ë‚´ì™¸ì˜ ì´ˆë‹¨ë¬¸ìœ¼ë¡œ** ìƒí™©ì„ ë¹„í‹€ì–´ ì›ƒìŒì„ ì£¼ì„¸ìš”.
    - ì˜ì¸í™”, ê³¼ì¥, ì˜ˆìƒì¹˜ ëª»í•œ ì—°ê²° ë“±ì„ í™œìš©í•˜ì—¬ ì°½ì˜ì ì¸ ìœ ë¨¸ë¥¼ êµ¬ì‚¬í•´ì£¼ì„¸ìš”.
4.  **ìœ ë¨¸ë¡œ í’€ì–´ë³¸ êµí›ˆ (humor_lesson):**
    - íŒ¨ëŸ¬ë””ì˜ ë‚´ìš©ì„ ì£¼ì‹ íˆ¬ìì™€ ì—°ê²°í•˜ì—¬, ê°€ë³ì§€ë§Œ ìƒê°í•´ë³¼ ë§Œí•œ êµí›ˆì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.
    - ì˜ˆì‹œ: "ì§„ì •í•œ ì €ì ì€ AIë„ ëª¨ë¥´ëŠ” ë²•, ë¶„ì‚° íˆ¬ìê°€ ì •ë‹µì´ë‹¤."
5.  **ë©´ì±…ì¡°í•­ (disclaimer):**
    - í•­ìƒ ë‹¤ìŒ ë¬¸êµ¬ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì£¼ì„¸ìš”: "ë©´ì±…ì¡°í•­:íŒ¨ëŸ¬ë””/íŠ¹ì •ê¸°ê´€,ê°œì¸ê³¼ ë¬´ê´€/íˆ¬ìì¡°ì–¸ì•„ë‹˜/ì¬ë¯¸ëª©ì "
    
## ğŸ’» ì¶œë ¥ í˜•ì‹
- ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.


- ê° í•„ë“œì˜ ê°’ì€ ë¬¸ìì—´(string)ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- **(ì ˆëŒ€ ê·œì¹™) ì ˆëŒ€ë¡œ ì´ëª¨ì§€(emoji)ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**

```json
{{
  "date": "{current_date}",
  "original_title": "{original_title_safe}",
  "parody_title": "ì—¬ê¸°ì— íŒ¨ëŸ¬ë”” ì œëª©",
  "setup": "ì—¬ê¸°ì— ìƒí™© ì„¤ì •",
  "punchline": "ì—¬ê¸°ì— ë°˜ì „/ì›ƒìŒ í¬ì¸íŠ¸",
  "humor_lesson": "ì—¬ê¸°ì— ìœ ë¨¸ë¡œ í’€ì–´ë³¸ êµí›ˆ",
  "disclaimer": "ë©´ì±…ì¡°í•­:íŒ¨ëŸ¬ë””/íŠ¹ì •ê¸°ê´€,ê°œì¸ê³¼ ë¬´ê´€/íˆ¬ìì¡°ì–¸ì•„ë‹˜/ì¬ë¯¸ëª©ì ",
  "source_url": "{news_link}"
}}
```

ìœ„ ê°€ì´ë“œë¼ì¸ì„ ì—„ê²©íˆ ë”°ë¼ì„œ, ì°½ì˜ì ì´ê³  ì¬ë¯¸ìˆëŠ” íŒ¨ëŸ¬ë””ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”."""

        print(f"  - [{i+1}/{len(top_news)}] íŒ¨ëŸ¬ë”” ìƒì„± ì¤‘...")
        
        response_text = ""
        error = None
        
        for attempt in range(2):
            try:
                retry_context = None
                if attempt > 0:
                    retry_context = {"malformed_json": response_text, "error_message": str(error)}
                
                parody_result_blocks = create_parody_with_claude(
                    news_content, parody_prompt, existing_parody_titles, retry_context
                )
                
                response_text = parody_result_blocks[0].text
                
                json_match = re.search(r'```json\n(\{.*?\})\n```', response_text, re.DOTALL)
                if not json_match:
                    json_text = response_text
                else:
                    json_text = json_match.group(1)

                parody_data = json.loads(json_text)
                
                parody_data_list.append(parody_data)
                existing_parody_titles.append(parody_data['parody_title']) # ìƒì„±ëœ ì œëª©ì„ ëª©ë¡ì— ì¶”ê°€
                print("    - ì„±ê³µ!")
                break
            
            except Exception as e:
                error = e
                print(f"    ! íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/2)")
                if attempt == 1:
                    print(f"    - ìµœì¢… ì‹¤íŒ¨: {e}")
    
    print(f"\\n[4/5] êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ ì¤‘... (ì´ {len(parody_data_list)}ê°œ)")
    save_to_gsheet(parody_data_list)
    
    print(f"\\n[5/5] ëª¨ë“  ì‘ì—… ì™„ë£Œ! {len(parody_data_list)}ê°œì˜ íŒ¨ëŸ¬ë””ê°€ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 