import os
import feedparser
from datetime import datetime, timedelta
from anthropic import Anthropic
from anthropic._exceptions import OverloadedError, RateLimitError, APIError
from dotenv import load_dotenv
from common_utils import get_gsheet, get_today_kst
import json
import re
from pathlib import Path
import time
from zoneinfo import ZoneInfo
from anthropic.types import MessageParam
import csv
import glob
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# .env íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì§€ì •í•˜ì—¬ ë¡œë“œ
env_path = Path('.') / '.env'
load_dotenv(dotenv_path=env_path, verbose=True)

# Claude AI API í‚¤
CLAUDE_API_KEY = os.getenv('CLAUDE_API_KEY')
if not CLAUDE_API_KEY:
    raise ValueError("CLAUDE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# í•œêµ­ ì‹œê°„ëŒ€ ì •ì˜
KST = ZoneInfo("Asia/Seoul")

def parse_rawdata(file_path='asset/rawdata.txt'):
    """rawdata.txt íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì„¤ì •ê°’ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    config = {}
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            current_key = None
            values = []
            for line in f:
                line = line.strip()
                if not line:
                    continue
                if line.startswith('[') and line.endswith(']'):
                    if current_key and values:
                        config[current_key] = values[0] if len(values) == 1 else values
                    current_key = line[1:-1]
                    values = []
                elif current_key:
                    values.append(line)
            if current_key and values:
                config[current_key] = values[0] if len(values) == 1 else values
    except FileNotFoundError:
        print(f"ì„¤ì • íŒŒì¼({file_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    return config

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
SHEET_NAME = 'today_stock_parody'
SHEET_ID = os.getenv('GSHEET_ID')
if not SHEET_ID:
    raise ValueError("GSHEET_ID í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def fetch_news(rss_url, days=7, min_news=20):
    """RSS í”¼ë“œì—ì„œ ìµœê·¼ days(ê¸°ë³¸ 7ì¼) ë‚´ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê³ , published_parsedê°€ ì—†ìœ¼ë©´ published/updated ë“± ë‹¤ë¥¸ í•„ë“œë„ í™œìš©. ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ë‚ ì§œ í•„í„° ì—†ì´ ì „ì²´ ìˆ˜ì§‘."""
    feed = feedparser.parse(rss_url)
    news_list = []
    today = get_today_kst().astimezone(KST).date()
    start_date = today - timedelta(days=days-1)
    print(f"[ë””ë²„ê·¸] feed.entries ê°œìˆ˜: {len(feed.entries)}")
    filtered_count = 0
    for entry in feed.entries:
        published_date = None
        # published_parsed ìš°ì„ , ì—†ìœ¼ë©´ published/updated ë“±ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
        if hasattr(entry, 'published_parsed') and isinstance(entry.published_parsed, time.struct_time):
            published_dt = datetime.fromtimestamp(time.mktime(entry.published_parsed), tz=KST)
            published_date = published_dt.date()
        elif hasattr(entry, 'published') and isinstance(entry.published, str):
            try:
                published_dt = datetime.strptime(entry.published[:10], '%Y-%m-%d')
                published_date = published_dt.date()
            except Exception:
                published_date = None
        elif hasattr(entry, 'updated_parsed') and isinstance(entry.updated_parsed, time.struct_time):
            published_dt = datetime.fromtimestamp(time.mktime(entry.updated_parsed), tz=KST)
            published_date = published_dt.date()
        # ë””ë²„ê¹…: ì‹¤ì œ ë‚ ì§œ ê°’ ì¶œë ¥
        print(f"[ë””ë²„ê·¸] published_date: {published_date}, start_date: {start_date}, today: {today}")
        if published_date and (start_date <= published_date <= today):
            title = entry.title
            summary = entry.summary if hasattr(entry, 'summary') else ''
            published = published_date.strftime('%Y-%m-%d') if published_date else ''
            link = entry.link if hasattr(entry, 'link') else ''
            news_item = {
                'title': title,
                'summary': summary,
                'published': published,
                'link': link
            }
            news_list.append(news_item)
        else:
            filtered_count += 1
    print(f"[ë””ë²„ê·¸] ë‚ ì§œ í•„í„° í†µê³¼ ë‰´ìŠ¤: {len(news_list)}, í•„í„°ë§ëœ ë‰´ìŠ¤: {filtered_count}")
    # ë§Œì•½ ë‰´ìŠ¤ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ë‚ ì§œ í•„í„° ì—†ì´ ì „ì²´ ìˆ˜ì§‘
    if len(news_list) < min_news:
        print("[ê²½ê³ ] ë‚ ì§œ í•„í„°ë¡œ ì¶©ë¶„í•œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‚ ì§œ í•„í„° ì—†ì´ ì „ì²´ ìˆ˜ì§‘ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        news_list = []
        for entry in feed.entries:
            title = entry.title
            summary = entry.summary if hasattr(entry, 'summary') else ''
            published = ''
            if hasattr(entry, 'published_parsed') and isinstance(entry.published_parsed, time.struct_time):
                published_dt = datetime.fromtimestamp(time.mktime(entry.published_parsed), tz=KST)
                published = published_dt.strftime('%Y-%m-%d')
            elif hasattr(entry, 'published') and isinstance(entry.published, str):
                published = entry.published[:10]
            link = entry.link if hasattr(entry, 'link') else ''
            news_item = {
                'title': title,
                'summary': summary,
                'published': published,
                'link': link
            }
            news_list.append(news_item)
        print(f"[ë””ë²„ê·¸] ë‚ ì§œ ë¬´ì‹œ ì „ì²´ ìˆ˜ì§‘ ë‰´ìŠ¤: {len(news_list)}")
    return news_list

def rank_news_by_importance_with_claude(news_list):
    """Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ëª©ë¡ì„ ì¤‘ìš”ë„ì— ë”°ë¼ ìˆœìœ„ ë§¤ê¸°ê¸°"""
    client = Anthropic(api_key=CLAUDE_API_KEY)

    formatted_news = ""
    for i, news in enumerate(news_list):
        formatted_news += f"ID: {i}\nì œëª©: {news['title']}\n\n"

    prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ê¸ˆìœµ ë‰´ìŠ¤ íë ˆì´í„°ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ì˜¤ëŠ˜ê³¼ ì–´ì œ ìˆ˜ì§‘ëœ ì£¼ì‹/ì¦ê¶Œ ê´€ë ¨ ë‰´ìŠ¤ ì „ì²´ ëª©ë¡ì…ë‹ˆë‹¤.
ì´ ì¤‘ì—ì„œ 'ë…ìë“¤ì´ ë§ì´ ì½ì„ ìˆ˜ ìˆê³ , ê´€ì‹¬ì„ ê°€ì§ˆ ë§Œí•œ ë‰´ìŠ¤'ë¥¼ 20ê°œ ê³¨ë¼, ê°€ì¥ ì¤‘ìš”í•œ ìˆœì„œëŒ€ë¡œ IDë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ ì¶œë ¥í•˜ì„¸ìš”.

## ğŸŒŸ ì¤‘ìš”ë„ íŒë‹¨ ê¸°ì¤€ (ì•„ë˜ ê¸°ì¤€ + ëŒ€ì¤‘ì  ê´€ì‹¬ë„/í™”ì œì„±/ë°”ì´ëŸ´ ê°€ëŠ¥ì„±ê¹Œì§€ ê³ ë ¤)

### 1. ì‹œì¥ ì „ì²´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (ê±°ì‹œê²½ì œ, ì •ì±…)
- í†µí™”ì •ì±…(í•œêµ­ì€í–‰, Fed ê¸ˆë¦¬, ì–‘ì ì™„í™”/ê¸´ì¶•)
- ê±°ì‹œê²½ì œ ì§€í‘œ(í™˜ìœ¨ ê¸‰ë³€ë™, ìœ ê°€, ë¬¼ê°€ì§€ìˆ˜)
- ì •ë¶€ ì •ì±…/ê·œì œ(ì„¸ë²• ê°œì •, ë¶€ë™ì‚° ì •ì±…, ì‚°ì—… ê·œì œ)

### 2. íŠ¹ì • ì‚°ì—… ë° ê¸°ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
- ë°˜ë„ì²´/AI/ìë™ì°¨/2ì°¨ì „ì§€/ë°”ì´ì˜¤/í”Œë«í¼/IT ë“± í•µì‹¬ ì‚°ì—… ë™í–¥
- ì£¼ìš” ê¸°ì—… ì‹¤ì , ì‹ ì œí’ˆ, ì´ìŠˆ

### 3. íˆ¬ìì/ëŒ€ì¤‘ ê´€ì‹¬ë„
- ì™¸êµ­ì¸/ê¸°ê´€ ë™í–¥, ëŒ€ê·œëª¨ ë§¤ìˆ˜/ë§¤ë„
- ì‚¬íšŒì  ì´ìŠˆ, ë°ˆ, í™”ì œì„±, ëŒ€ì¤‘ì  ê¶ê¸ˆì¦

## ğŸ“° ë‰´ìŠ¤ ëª©ë¡
{formatted_news}

## ğŸ’» ì¶œë ¥ í˜•ì‹
- ë‹¤ë¥¸ ì„¤ëª… ì—†ì´, ê°€ì¥ ì¤‘ìš”ë„ê°€ ë†’ì€ ë‰´ìŠ¤ 20ê°œ IDë¥¼ **ì‰¼í‘œ(,)ë¡œë§Œ êµ¬ë¶„**í•˜ì—¬ í•œ ì¤„ë¡œ ì¶œë ¥
- ì˜ˆì‹œ: 5,12,3,1,8,2,7,11,0,4

ê°€ì¥ ì¤‘ìš”í•œ 20ê°œ ë‰´ìŠ¤ì˜ IDë¥¼ ìˆœì„œëŒ€ë¡œ ì‘ì„±í•˜ì„¸ìš”:
"""

    try:
        response = safe_api_call(
            client, 
            [MessageParam(role="user", content=prompt)],
            max_retries=5,
            base_delay=3
        )
    except Exception as e:
        print(f"  ! Claude API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        print("  ! ì›ë˜ ìˆœì„œëŒ€ë¡œ ë‰´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return news_list
    response_block = response.content[0]
    response_text = getattr(response_block, 'text', None) or getattr(response_block, 'content', None) or str(response_block)
    response_text = response_text.strip()
    
    try:
        ranked_ids = [int(id_str.strip()) for id_str in response_text.split(',')]
        valid_ranked_ids = [id_val for id_val in ranked_ids if 0 <= id_val < len(news_list)]
        
        ranked_news = [news_list[i] for i in valid_ranked_ids]
        unranked_news_ids = set(range(len(news_list))) - set(valid_ranked_ids)
        unranked_news = [news_list[i] for i in unranked_news_ids]

        return ranked_news + unranked_news
    except ValueError:
        print("  ! AI ìˆœìœ„ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨. ì›ë˜ ìˆœì„œëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return news_list

def create_parody_with_claude(news_content, original_prompt, existing_content, retry_context=None):
    """Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ íŒ¨ëŸ¬ë”” ìƒì„± (ì „ì²´ ì½˜í…ì¸  ì¤‘ë³µ ë°©ì§€ ë° ìë™ ë³µêµ¬ ê¸°ëŠ¥ í¬í•¨)"""
    client = Anthropic(api_key=CLAUDE_API_KEY)
    
    # ê°•í™”ëœ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    if existing_content:
        duplication_warning = (
            "\n\n## ğŸš¨ (ë§¤ìš° ì¤‘ìš”) ì ˆëŒ€ì  ì¤‘ë³µ ë°©ì§€ ê·œì¹™\n"
            "- ì•„ë˜ëŠ” ì´ë¯¸ ìƒì„±ëœ ëª¨ë“  íŒ¨ëŸ¬ë”” ì½˜í…ì¸ ì…ë‹ˆë‹¤.\n"
            "- ì ˆëŒ€ë¡œ ì•„ë˜ì™€ ìœ ì‚¬í•œ ì œëª©, í‘œí˜„, íŒ¨í„´, ìŠ¤íƒ€ì¼ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "- ì™„ì „íˆ ìƒˆë¡­ê³  ì°½ì˜ì ì¸ ì½˜í…ì¸ ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.\n\n"
            "### ğŸ“œ ì´ë¯¸ ìƒì„±ëœ ì½˜í…ì¸  ëª©ë¡:\n"
        )
        
        for i, content in enumerate(existing_content):
            duplication_warning += f"\n[{i+1}]\n"
            duplication_warning += f"ì œëª©: {content.get('parody_title', '')}\n"
            duplication_warning += f"Setup: {content.get('setup', '')}\n"
            duplication_warning += f"Punchline: {content.get('punchline', '')}\n"
            duplication_warning += f"Lesson: {content.get('humor_lesson', '')}\n"
        
        duplication_warning += (
            "\n\n## âŒ ì ˆëŒ€ ê¸ˆì§€ íŒ¨í„´ë“¤\n"
            "- 'ì›”ê¸‰ì€ ê·¸ëŒ€ë¡œì¸ë°' í‘œí˜„ ê¸ˆì§€\n"
            "- 'ê°œë¯¸ë“¤ ì´ëŸ´ ì¤„ì´ì•¼' í‘œí˜„ ê¸ˆì§€\n"
            "- 'ë™ë£Œ: â—‹â—‹ ë‚˜: â–³â–³ ë™ë£Œ: ìš°ë¦¬ íšŒì‚¬ë„...' ëŒ€í™” íŒ¨í„´ ê¸ˆì§€\n"
            "- 'ê³„ë‹¨ìœ¼ë¡œ ì˜¤ë¥´ê³  ì°½ë¬¸/ì—˜ë¦¬ë² ì´í„°ë¡œ' í‘œí˜„ ê¸ˆì§€\n"
            "- 'ì²œë¬¸í•™ì ', 'ì²œì •ë¶€ì§€' ë“± ê³¼ì¥ í‘œí˜„ ë°˜ë³µ ê¸ˆì§€\n"
            "- 'ë˜ ëš!', 'ë˜ ì¾…!' ë“± ì˜ì„±ì–´ ë°˜ë³µ ê¸ˆì§€\n\n"
            "## âœ… í•„ìˆ˜ ë‹¤ì–‘í™” ìš”êµ¬ì‚¬í•­\n"
            "- ì œëª©: ìˆ«ìí˜•/ì§ˆë¬¸í˜•/ê°íƒ„í˜•/ë¹„êµí˜• ë“± ì™„ì „íˆ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©\n"
            "- Setup: ì¶œê·¼/ì ì‹¬/í‡´ê·¼/ì£¼ë§/íœ´ê°€ ë“± ë‹¤ì–‘í•œ ìƒí™© ì„¤ì •\n"
            "- Punchline: ë…ë°±/ìƒí™©ê·¹/ë°ˆ/íŒ¨ëŸ¬ë””/ì¸í„°ë·° ë“± í˜•ì‹ ë³€í™”\n"
            "- Lesson: ì‹¤ìš©ì¡°ì–¸/ëª…ì–¸/ìœ ë¨¸/ê²©ì–¸ ë“± í†¤ì•¤ë§¤ë„ˆ ë³€í™”\n"
        )
        
        original_prompt += duplication_warning

    messages = [MessageParam(role="user", content=original_prompt)]
    
    if retry_context:
        user_message = f"""ì´ì „ ì‘ë‹µì— ì˜¤ë¥˜ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
## ì´ì „ ì‘ë‹µ (ì˜ëª»ëœ ë¶€ë¶„)
{retry_context['malformed_json']}
## ë°œìƒí•œ ì˜¤ë¥˜
{retry_context['error_message']}
ìœ„ ì˜¤ë¥˜ë¥¼ ì°¸ê³ í•˜ì—¬, ìœ íš¨í•œ JSON í˜•ì‹ì— ë§ì¶° ìˆ˜ì •ëœ ì‘ë‹µì„ ```json ... ``` ì½”ë“œ ë¸”ë¡ ì•ˆì— ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
        # ë¹ˆ ë©”ì‹œì§€ ë°©ì§€ë¥¼ ìœ„í•´ ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ ì¶”ê°€
        if retry_context['malformed_json'].strip():
            messages.append(MessageParam(role="assistant", content=retry_context['malformed_json']))
        messages.append(MessageParam(role="user", content=user_message))

    try:
        response = safe_api_call(client, messages, max_retries=5, base_delay=3)
    except Exception as e:
        print(f"  ! Claude API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise e
    
    return response.content

def save_to_gsheet(parody_data_list):
    """íŒ¨ëŸ¬ë”” ë°ì´í„°ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ (ì‹œíŠ¸ ì´ˆê¸°í™” í›„ ì €ì¥)"""
    sheet = get_gsheet(SHEET_ID, 'today_stock_parody')
    
    # ì‹œíŠ¸ ì´ˆê¸°í™”
    sheet.clear()
    
    # í—¤ë” ì¶”ê°€
    headers = [
        'date', 'original_title', 'parody_title', 'setup', 
        'punchline', 'humor_lesson', 'disclaimer', 'source_url'
    ]
    sheet.append_row(headers)
    
    # ë°ì´í„° ì¶”ê°€
    for parody_data in parody_data_list:
        row = [
            parody_data.get('date', ''),
            parody_data.get('original_title', ''),
            parody_data.get('parody_title', ''),
            parody_data.get('setup', ''),
            parody_data.get('punchline', ''),
            parody_data.get('humor_lesson', ''),
            parody_data.get('disclaimer', ''),
            parody_data.get('source_url', '')
        ]
        sheet.append_row(row)

def save_to_csv(parody_data_list):
    """íŒ¨ëŸ¬ë”” ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
    try:
        # í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±
        now = get_today_kst()
        timestamp = now.strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}_gsni.csv"
        
        # CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
        csv_dir = "csv_data"
        os.makedirs(csv_dir, exist_ok=True)
        csv_path = os.path.join(csv_dir, filename)
        
        # ê¸°ì¡´ CSV íŒŒì¼ ëª¨ë‘ ì‚­ì œ (ìƒˆë¡œìš´ íŒŒì¼ë§Œ ìƒì„±)
        print("ğŸ§¹ ê¸°ì¡´ CSV íŒŒì¼ ì •ë¦¬ ì¤‘...")
        csv_files = glob.glob(os.path.join(csv_dir, '*.csv'))
        if len(csv_files) > 0:
            deleted_count = 0
            for old_file in csv_files:
                try:
                    os.remove(old_file)
                    print(f"   - ê¸°ì¡´ CSV íŒŒì¼ ì‚­ì œ: {os.path.basename(old_file)}")
                    deleted_count += 1
                except Exception as e:
                    print(f"   - íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {os.path.basename(old_file)} ({e})")
            print(f"   - ì´ {deleted_count}ê°œ ê¸°ì¡´ CSV íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
        else:
            print("   - ì‚­ì œí•  ê¸°ì¡´ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        # CSV íŒŒì¼ ìƒì„±
        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as csvfile:
            fieldnames = [
                'date', 'original_title', 'parody_title', 'setup', 
                'punchline', 'humor_lesson', 'disclaimer', 'source_url'
            ]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            # í—¤ë” ì‘ì„±
            writer.writeheader()
            
            # ë°ì´í„° ì‘ì„±
            for parody_data in parody_data_list:
                writer.writerow(parody_data)
        
        print(f"ğŸ“„ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_path}")
        return csv_path
        
    except Exception as e:
        print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

def upload_to_google_drive(csv_path, folder_id):
    """CSV íŒŒì¼ì„ Google Driveì— ì—…ë¡œë“œ"""
    try:
        # Google Drive API ì¸ì¦
        creds = None
        token_path = 'youtube_uploader/token.json'
        
        if os.path.exists(token_path):
            creds = Credentials.from_authorized_user_file(token_path, 
                ['https://www.googleapis.com/auth/drive.file'])
        
        if not creds:
            print("âš ï¸ Google Drive ì¸ì¦ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # Google Drive ì„œë¹„ìŠ¤ ìƒì„±
        service = build('drive', 'v3', credentials=creds)
        
        # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì„¤ì •
        file_metadata = {
            'name': os.path.basename(csv_path),
            'parents': [folder_id]
        }
        
        # íŒŒì¼ ì—…ë¡œë“œ
        media = MediaFileUpload(csv_path, mimetype='text/csv', resumable=True)
        file = service.files().create(
            body=file_metadata,
            media_body=media,
            fields='id'
        ).execute()
        
        file_id = file.get('id')
        file_url = f"https://drive.google.com/file/d/{file_id}/view"
        
        print(f"â˜ï¸ Google Drive ì—…ë¡œë“œ ì™„ë£Œ: {file_url}")
        return file_url
        
    except Exception as e:
        print(f"âŒ Google Drive ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def safe_api_call(client, messages, max_retries=3, base_delay=2):
    """API í˜¸ì¶œì„ ì•ˆì „í•˜ê²Œ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    for attempt in range(max_retries):
        try:
            response = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=2000,
                temperature=0.8,
                system="",
                messages=messages
            )
            return response
        except OverloadedError as e:
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                print(f"  ! API ê³¼ë¶€í•˜ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries}). {delay}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(delay)
            else:
                print(f"  ! ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. API ê³¼ë¶€í•˜ë¡œ ì¸í•œ ì‹¤íŒ¨.")
                raise e
        except (RateLimitError, APIError) as e:
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)
                print(f"  ! API ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries}). {delay}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(delay)
            else:
                print(f"  ! ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. API ì˜¤ë¥˜ë¡œ ì¸í•œ ì‹¤íŒ¨.")
                raise e
        except Exception as e:
            print(f"  ! ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            raise e

def main():
    try:
        print("[1/5] í•œê²½ ì¦ê¶Œë‰´ìŠ¤ë§Œ ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ë‰´ìŠ¤ ì„ ë³„ ì¤‘...")
        raw_config = parse_rawdata()
        if not raw_config:
            print("[ì˜¤ë¥˜] ì„¤ì • íŒŒì¼(asset/rawdata.txt)ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # ì¹´ë“œë‰´ìŠ¤ ê°œìˆ˜ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        card_count_config = raw_config.get('ì¹´ë“œë‰´ìŠ¤ê°œìˆ˜', ['ì¹´ë“œë‰´ìŠ¤ ê°œìˆ˜ : ìµœëŒ€ 20ê°œ.'])
        card_count_str = card_count_config[0] if isinstance(card_count_config, list) else card_count_config
        card_count = 20  # ê¸°ë³¸ê°’
        
        # "ì¹´ë“œë‰´ìŠ¤ ê°œìˆ˜ : ìµœëŒ€ Xê°œ." í˜•ì‹ì—ì„œ ìˆ«ì ì¶”ì¶œ
        import re
        count_match = re.search(r'ìµœëŒ€ (\d+)ê°œ', card_count_str)
        if count_match:
            card_count = int(count_match.group(1))
            print(f"[ì„¤ì •] ì¹´ë“œë‰´ìŠ¤ ê°œìˆ˜: {card_count}ê°œ")
        else:
            print(f"[ì„¤ì •] ì¹´ë“œë‰´ìŠ¤ ê°œìˆ˜ íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ {card_count}ê°œ ì‚¬ìš©")
        
        rss_urls = raw_config.get('RSS_URL ì§€ì •', [])
        if isinstance(rss_urls, str):
            rss_urls = [rss_urls]
        if not rss_urls:
            print("[ì˜¤ë¥˜] asset/rawdata.txt íŒŒì¼ì—ì„œ 'RSS_URL ì§€ì •'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        rss_url = rss_urls[0]  # í•œê²½ ì¦ê¶Œë‰´ìŠ¤ë§Œ ì‚¬ìš©
        all_news = fetch_news(rss_url)
        if not all_news:
            print("\n[ì˜¤ë¥˜] í•œê²½ ì¦ê¶Œë‰´ìŠ¤ì—ì„œ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        print(f"\n[2/5] Claude 3.5ê°€ ë…ìë“¤ì´ ê°€ì¥ ê´€ì‹¬ì„ ê°€ì§ˆ ë§Œí•œ ë‰´ìŠ¤ {card_count}ê°œë¥¼ ì§ì ‘ ì„ ì •í•©ë‹ˆë‹¤...")
        ranked_news = rank_news_by_importance_with_claude(all_news)
        top_news = ranked_news[:card_count]
        print(f"\n[2.5/5] ì´ {len(top_news)}ê°œ ë‰´ìŠ¤ ì„ ë³„ ì™„ë£Œ! íŒ¨ëŸ¬ë”” ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        print(f"\n[3/5] ì¤‘ìš”ë„ ìƒìœ„ {len(top_news)}ê°œ ë‰´ìŠ¤ë¡œ íŒ¨ëŸ¬ë”” ìƒì„± ì¤‘...")
        parody_data_list = []
        today_str = get_today_kst().strftime('%Y-%m-%d')
        existing_content = []  # ì „ì²´ ì½˜í…ì¸  ì¶”ì 
        
        for i, news in enumerate(top_news):
            news_content = f"ì œëª©: {news['title']}\në‚´ìš©: {news['summary']}\në§í¬: {news['link']}"
            current_date = today_str
            original_title_safe = news['title'].replace('"', "'")
            news_link = news['link']
            news_title = news['title']
            news_summary = news['summary']
            
            # ë‹¤ì–‘ì„±ì„ ìœ„í•œ ë™ì  ìŠ¤íƒ€ì¼ ì§€ì •
            style_index = i % 6
            style_instructions = [
                "ìˆ«ì ì¶©ê²©í˜• ìŠ¤íƒ€ì¼: êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜ ë†€ë¼ì›€ í‘œí˜„",
                "ì§ˆë¬¸í˜• ìŠ¤íƒ€ì¼: ê¶ê¸ˆì¦ì„ ìœ ë°œí•˜ëŠ” ì§ˆë¬¸ìœ¼ë¡œ ì œëª© êµ¬ì„±", 
                "ë¹„êµ/ëŒ€ì¡°í˜• ìŠ¤íƒ€ì¼: A vs B ë˜ëŠ” ê³¼ê±°ì™€ í˜„ì¬ ë¹„êµ",
                "ìƒí™©ê·¹í˜• ìŠ¤íƒ€ì¼: íŠ¹ì • ìƒí™©ì´ë‚˜ ì¥ë©´ì„ ì—°ìƒì‹œí‚¤ëŠ” ì œëª©",
                "ë°ˆ/íŠ¸ë Œë“œí˜• ìŠ¤íƒ€ì¼: ìµœì‹  ì¸í„°ë„· ë¬¸í™”ë‚˜ ë°ˆ í™œìš©",
                "í˜„ì‹¤ í’ìí˜• ìŠ¤íƒ€ì¼: ì§ì¥ì¸/ê°œë¯¸ í˜„ì‹¤ì„ ìœ„íŠ¸ìˆê²Œ í’ì"
            ]
            
            setup_styles = [
                "ì¶œê·¼ê¸¸ ì§€í•˜ì² ì—ì„œ ë‰´ìŠ¤ ë³´ëŠ” ìƒí™©",
                "ì ì‹¬ì‹œê°„ ë™ë£Œë“¤ê³¼ ëŒ€í™”í•˜ëŠ” ìƒí™©", 
                "í‡´ê·¼ í›„ ì§‘ì—ì„œ ì£¼ì‹ í™•ì¸í•˜ëŠ” ìƒí™©",
                "ì£¼ë§ ì¹´í˜ì—ì„œ íˆ¬ì ê³ ë¯¼í•˜ëŠ” ìƒí™©",
                "íšŒì‚¬ í™”ì¥ì‹¤ì—ì„œ ëª°ë˜ ì£¼ì‹ ë³´ëŠ” ìƒí™©",
                "ìƒˆë²½ì— í•´ì™¸ ì¦ì‹œ í™•ì¸í•˜ëŠ” ìƒí™©"
            ]
            
            punchline_styles = [
                "ë‚´ì  ë…ë°± í˜•ì‹ìœ¼ë¡œ ì†”ì§í•œ ì‹¬ê²½ í‘œí˜„",
                "ê°€ì¡±/ì¹œêµ¬ì™€ì˜ ëŒ€í™” í˜•ì‹",
                "SNS ëŒ“ê¸€ì´ë‚˜ ë©”ì‹œì§€ í˜•ì‹",
                "ë‰´ìŠ¤ ì¸í„°ë·° íŒ¨ëŸ¬ë”” í˜•ì‹", 
                "ê´‘ê³ ë‚˜ í™ë³´ ë¬¸êµ¬ íŒ¨ëŸ¬ë””",
                "ì˜í™”/ë“œë¼ë§ˆ ëŒ€ì‚¬ íŒ¨ëŸ¬ë””"
            ]
            
            parody_prompt = f"""
ë‹¹ì‹ ì€ ì¡°íšŒìˆ˜ ê¸‰ìƒìŠ¹ì„ ëª©í‘œë¡œ í•˜ëŠ” ì¦ê¶Œ ë‰´ìŠ¤ íŒ¨ëŸ¬ë”” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ã€í•µì‹¬ ë¯¸ì…˜ã€‘
- 30-50ëŒ€ ì§ì¥ì¸ íƒ€ê²Ÿ, 90ì´ˆ ìˆí¼ ì½˜í…ì¸ 
- ë°”ì´ëŸ´ ìš”ì†Œ ê·¹ëŒ€í™”, ë…ì°½ì„±ê³¼ ì°¨ë³„ì„± í™•ë³´
- ê¸°ì¡´ ë»”í•œ íŒ¨í„´ ì™„ì „ íƒˆí”¼

ã€ì´ë²ˆ ì½˜í…ì¸  ìŠ¤íƒ€ì¼ ì§€ì •ã€‘
- ì œëª© ìŠ¤íƒ€ì¼: {style_instructions[style_index]}
- Setup ìƒí™©: {setup_styles[style_index]}  
- Punchline í˜•ì‹: {punchline_styles[style_index]}

ã€ì œëª© ì‘ì„± ì›ì¹™ã€‘
- 20ì ì´ë‚´, í´ë¦­ ìš•êµ¬ í­ë°œì‹œí‚¤ëŠ” í‚¬ë§ íƒ€ì´í‹€
- ì§€ì •ëœ ìŠ¤íƒ€ì¼ì— ë§ì¶° ì™„ì „íˆ ìƒˆë¡œìš´ ì ‘ê·¼
- êµ¬ì²´ì  ìˆ«ì/ìƒí™©/ê°ì • í¬í•¨í•˜ë˜ ë»”í•œ í‘œí˜„ ê¸ˆì§€

ã€ì¹´ë“œë‰´ìŠ¤ êµ¬ì¡°ã€‘
- parody_title: ì§€ì • ìŠ¤íƒ€ì¼ì˜ 20ì ì´ë‚´ ë…ì°½ì  ì œëª©
- setup: ì§€ì • ìƒí™©ì— ë§ëŠ” í˜„ì‹¤ì ì´ê³  ê³µê°ë˜ëŠ” í•œ ì¤„
- punchline: ì§€ì • í˜•ì‹ì˜ ìœ„íŠ¸ìˆê³  ë°˜ì „ìˆëŠ” 35ì ì´ë‚´ ë©˜íŠ¸
- humor_lesson: ì‹¤ìš©ì  íˆ¬ì ì¡°ì–¸ì´ë‚˜ ì¸ìƒ ê²©ì–¸ (ê¸°ì¡´ ë»”í•œ ê²©ì–¸ ê¸ˆì§€)
- disclaimer: 'ë©´ì±…ì¡°í•­:íŒ¨ëŸ¬ë””/íŠ¹ì •ê¸°ê´€,ê°œì¸ê³¼ ë¬´ê´€/íˆ¬ìì¡°ì–¸ì•„ë‹˜/ì¬ë¯¸ëª©ì '
- source_url: ì›ë³¸ ë‰´ìŠ¤ ë§í¬

ã€ìƒˆë¡œìš´ í‘œí˜„ íŒ¨í„´ ì˜ˆì‹œã€‘
ì œëª©: "ì‚¼ì„± 20% ê¸‰ë“±, ì´ì¬ìš© ë§ˆë²•?"
      "4ì¡°ë‹¬ëŸ¬ ì—”ë¹„ë””ì•„, í•œêµ­ GDP ë„˜ì—ˆë‹¤"
      "íŒŒì›” í•´ì„ì„¤? ê°œë¯¸ë“¤ 'ìš°ë¦¬ë„ í•´ì„ë˜ê³ íŒŒ'"
      "ì½”ì¸ ë²•ì•ˆ í†µê³¼, ë¼ë©´ë„ ì•”í˜¸í™”íë¡œ?"

Setup: "ì§€í•˜ì² ì—ì„œ ì‚¼ì„± ë‰´ìŠ¤ ë³´ìë§ˆì ì£¼ì‹ ì•± ì¼°ë‹¤"
       "ì ì‹¬ì‹œê°„, ë™ë£Œê°€ 'ì—”ë¹„ë””ì•„ ë­ëƒ'ê³  ë¬¼ì–´ë´¤ë‹¤"  
       "í‡´ê·¼ í›„ ì§‘ì—ì„œ ì½”ì¸ ë‰´ìŠ¤ì— í™”ë“¤ì§í–ˆë‹¤"

Punchline: "ë‚˜: (ì†ë§ˆìŒ) 'ì´ì œ ì›”ê¸‰ë³´ë‹¤ ì£¼ì‹ì´ ë” ì¤‘ìš”í•´...'"
           "ì•„ë‚´: 'ë˜ ì£¼ì‹í•´?' ë‚˜: 'ì´ê±´ íˆ¬ìì•¼!' ì•„ë‚´: 'ë§í•˜ë©´ ì´í˜¼ì´ì•¼!'"
           "ëŒ“ê¸€: 'ëŒ€ë°•! ë‚˜ë„ ì‚¬ê³ ì‹¶ë‹¤' â†’ ë‹µê¸€: 'ì´ë¯¸ ëŠ¦ì—ˆì–´ìš” ã… ã… '"

ã€ì¶œë ¥ ì˜ˆì‹œã€‘
```json
{{
  "date": "{current_date}",
  "original_title": "{original_title_safe}",
  "parody_title": "ì‚¼ì„± 20% í­ë“±! ì´ì¬ìš© ë§ˆë²• ì‹¤í™”?",
  "setup": "ì§€í•˜ì²  2í˜¸ì„ ì—ì„œ ì‚¼ì„± ë‰´ìŠ¤ ë³´ìë§ˆì ì£¼ì‹ ì•±ì„ ì¼°ë‹¤.",
  "punchline": "ë‚˜: (ì†ë§ˆìŒ) 'ë“œë””ì–´ ë‚´ ì‚¼ì„±ì „ìê°€...' ì˜† ì•„ì €ì”¨: 'ë­˜ ê·¸ë ‡ê²Œ ì›ƒì–´?' ë‚˜: 'ë¡œë˜ ë‹¹ì²¨ëì–´ìš”!'",
  "humor_lesson": "íˆ¬ìì˜ í•µì‹¬ì€ íƒ€ì´ë°ì´ ì•„ë‹ˆë¼ ì¸ë‚´ì‹¬ì´ë‹¤. ê¸‰ë“±ë„ ì¢‹ì§€ë§Œ ì¥ê¸° ê´€ì ì„ ìƒì§€ ë§ì.",
  "disclaimer": "ë©´ì±…ì¡°í•­:íŒ¨ëŸ¬ë””/íŠ¹ì •ê¸°ê´€,ê°œì¸ê³¼ ë¬´ê´€/íˆ¬ìì¡°ì–¸ì•„ë‹˜/ì¬ë¯¸ëª©ì ",
  "source_url": "{news_link}"
}}
```

ã€ì ˆëŒ€ ê·œì¹™ã€‘
- ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë¡œë§Œ ì¶œë ¥ (ì„¤ëª…/í•´ì„¤ ì—†ì´)
- ì´ëª¨ì§€ ì ˆëŒ€ ê¸ˆì§€, ëŒ€ì‹  !!!, ???, ~~~ ë“± ì ê·¹ í™œìš©
- ì§€ì •ëœ ìŠ¤íƒ€ì¼ì— ë§ì¶° ê¸°ì¡´ê³¼ ì™„ì „íˆ ë‹¤ë¥¸ ì ‘ê·¼
- ëª¨ë“  í•„ë“œë¥¼ ë¹ˆ ê°’ ì—†ì´ ì°½ì˜ì ìœ¼ë¡œ ì±„ìš°ê¸°
- ë»”í•œ íŒ¨í„´/í‘œí˜„/êµ¬ì¡° ì™„ì „ ë°°ì œ

ì•„ë˜ëŠ” ì…ë ¥ ë‰´ìŠ¤ì…ë‹ˆë‹¤.
- ì œëª©: {news_title}
- ìš”ì•½: {news_summary}
- ë§í¬: {news_link}

ì§€ì •ëœ ìŠ¤íƒ€ì¼ê³¼ ìƒí™©ì— ë§ì¶°, ê¸°ì¡´ê³¼ ì™„ì „íˆ ì°¨ë³„í™”ëœ ë…ì°½ì  íŒ¨ëŸ¬ë””ë¥¼ ìƒì„±í•˜ì„¸ìš”.
"""
            print(f"  - [{i+1}/{len(top_news)}] íŒ¨ëŸ¬ë”” ìƒì„± ì¤‘... (ìŠ¤íƒ€ì¼: {style_instructions[style_index][:15]}...)")
            response_text = ""
            error = None
            for attempt in range(3):  # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
                try:
                    retry_context = None
                    if attempt > 0:
                        retry_context = {"malformed_json": response_text, "error_message": str(error)}
                    
                    # API í˜¸ì¶œ ì „ ì ì‹œ ëŒ€ê¸° (API ë¶€í•˜ ë¶„ì‚°)
                    if attempt > 0:
                        time.sleep(2)
                    
                    parody_result_blocks = create_parody_with_claude(
                        news_content, parody_prompt, existing_content, retry_context
                    )
                    response_block = parody_result_blocks[0]
                    response_text = getattr(response_block, 'text', None) or getattr(response_block, 'content', None) or str(response_block)
                    
                    # JSON íŒŒì‹± ê°œì„ 
                    json_match = re.search(r'```json\n(\{.*?\})\n```', response_text, re.DOTALL)
                    if not json_match:
                        start_index = response_text.find('{')
                        end_index = response_text.rfind('}')
                        if start_index != -1 and end_index != -1 and start_index < end_index:
                            json_text = response_text[start_index:end_index+1]
                        else:
                            # JSONì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ êµ¬ì¡° ìƒì„±
                            json_text = f'{{"date": "{current_date}", "original_title": "{original_title_safe}", "parody_title": "API ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì œëª©", "setup": "API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "punchline": "ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", "humor_lesson": "API ì„œë²„ê°€ ê³¼ë¶€í•˜ ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "disclaimer": "ë©´ì±…ì¡°í•­:íŒ¨ëŸ¬ë””/íŠ¹ì •ê¸°ê´€,ê°œì¸ê³¼ ë¬´ê´€/íˆ¬ìì¡°ì–¸ì•„ë‹˜/ì¬ë¯¸ëª©ì ", "source_url": "{news_link}"}}'
                    else:
                        json_text = json_match.group(1)
                    
                    parody_data = json.loads(json_text)
                    parody_data_list.append(parody_data)
                    existing_content.append(parody_data)  # ì „ì²´ ì½˜í…ì¸  ì¶”ê°€
                    print("    - ì„±ê³µ!")
                    break
                except Exception as e:
                    error = e
                    print(f"    ! íŒ¨ëŸ¬ë”” ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/3): {e}")
                    if attempt == 2:  # ë§ˆì§€ë§‰ ì‹œë„
                        print(f"    - ìµœì¢… ì‹¤íŒ¨: {e}")
                        # ê¸°ë³¸ íŒ¨ëŸ¬ë”” ë°ì´í„° ìƒì„±
                        default_parody = {
                            'date': current_date,
                            'original_title': original_title_safe,
                            'parody_title': f"API ì˜¤ë¥˜ - {news_title[:20]}...",
                            'setup': "API ì„œë²„ ê³¼ë¶€í•˜ë¡œ ì¸í•œ ê¸°ë³¸ ì„¤ì •",
                            'punchline': "ì„œë²„ê°€ ë³µêµ¬ë˜ë©´ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”",
                            'humor_lesson': "íˆ¬ìë³´ë‹¤ ì¤‘ìš”í•œ ê²ƒì€ ì¸ë‚´ì‹¬ì…ë‹ˆë‹¤",
                            'disclaimer': "ë©´ì±…ì¡°í•­:íŒ¨ëŸ¬ë””/íŠ¹ì •ê¸°ê´€,ê°œì¸ê³¼ ë¬´ê´€/íˆ¬ìì¡°ì–¸ì•„ë‹˜/ì¬ë¯¸ëª©ì ",
                            'source_url': news_link
                        }
                        parody_data_list.append(default_parody)
                        existing_content.append(default_parody)
                        print("    - ê¸°ë³¸ íŒ¨ëŸ¬ë”” ë°ì´í„°ë¡œ ëŒ€ì²´")
        if not parody_data_list:
            print("\n[ì˜¤ë¥˜] íŒ¨ëŸ¬ë”” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        print(f"\n[4/5] ì´ {len(parody_data_list)}ê°œ íŒ¨ëŸ¬ë”” ìƒì„± ì™„ë£Œ!")
        
        # êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        try:
            save_to_gsheet(parody_data_list)
            print(f"\n[5/5] êµ¬ê¸€ ì‹œíŠ¸ì— íŒ¨ëŸ¬ë”” ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"\n[5/5] êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ service_account.json íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # CSV íŒŒì¼ ì €ì¥
        csv_path = save_to_csv(parody_data_list)
        if csv_path:
            print(f"ğŸ“„ CSV íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {csv_path}")
            print(f"ğŸ“ íŒŒì¼ ê²½ë¡œ: {os.path.abspath(csv_path)}")
            
            # Google Drive ì—…ë¡œë“œ ì‹œë„ (ì„ íƒì‚¬í•­)
            try:
                google_drive_folder_id = "1dpMzrdIl5iL8gmkrxwtiWBCOiMgU-toG"
                drive_url = upload_to_google_drive(csv_path, google_drive_folder_id)
                if drive_url:
                    print(f"â˜ï¸ Google Drive ì—…ë¡œë“œ ì„±ê³µ: {drive_url}")
                else:
                    print("â„¹ï¸ Google Drive ì—…ë¡œë“œ ê±´ë„ˆëœ€ (ë¡œì»¬ CSV íŒŒì¼ë§Œ ìƒì„±ë¨)")
            except Exception as e:
                print(f"â„¹ï¸ Google Drive ì—…ë¡œë“œ ê±´ë„ˆëœ€: {e}")
                print("ğŸ’¡ Google Drive ì—…ë¡œë“œë¥¼ ì›í•œë‹¤ë©´ generate_drive_token.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            print("âŒ CSV íŒŒì¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ì‹¤íŒ¨ ì‹œ ì½˜ì†”ì— ë°ì´í„° ì¶œë ¥
        if not csv_path:
            print("ğŸ“‹ ìƒì„±ëœ íŒ¨ëŸ¬ë”” ë°ì´í„°:")
            for i, data in enumerate(parody_data_list, 1):
                print(f"\n--- íŒ¨ëŸ¬ë”” {i} ---")
                print(f"ì œëª©: {data.get('parody_title', 'N/A')}")
                print(f"Setup: {data.get('setup', 'N/A')}")
                print(f"Punchline: {data.get('punchline', 'N/A')}")
                print(f"Lesson: {data.get('humor_lesson', 'N/A')}")
                print(f"ì›ë³¸: {data.get('original_title', 'N/A')}")
        
        print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n[ì¹˜ëª…ì  ì˜¤ë¥˜] í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()