import os
import feedparser
from datetime import datetime, timedelta
from anthropic import Anthropic
from dotenv import load_dotenv
from common_utils import get_gsheet, get_today_kst
import json
import re
from pathlib import Path
import time
from zoneinfo import ZoneInfo
from anthropic.types import MessageParam

# .env íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì§€ì •í•˜ì—¬ ë¡œë“œ
env_path = Path('.') / '.env'
load_dotenv(dotenv_path=env_path, verbose=True)

# Claude AI API í‚¤
CLAUDE_API_KEY = os.getenv('CLAUDE_API_KEY')
if not CLAUDE_API_KEY:
    raise ValueError("CLAUDE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# í•œêµ­ ì‹œê°„ëŒ€ ì •ì˜
KST = ZoneInfo("Asia/Seoul")

def parse_rawdata(file_path='asset/rawdata.txt'):
    """rawdata.txt íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì„¤ì •ê°’ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    config = {}
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            current_key = None
            values = []
            for line in f:
                line = line.strip()
                if not line:
                    continue
                if line.startswith('[') and line.endswith(']'):
                    if current_key and values:
                        config[current_key] = values[0] if len(values) == 1 else values
                    current_key = line[1:-1]
                    values = []
                elif current_key:
                    values.append(line)
            if current_key and values:
                config[current_key] = values[0] if len(values) == 1 else values
    except FileNotFoundError:
        print(f"ì„¤ì • íŒŒì¼({file_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    return config

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
SHEET_NAME = 'today_stock_parody'
SHEET_ID = os.getenv('GSHEET_ID')
if not SHEET_ID:
    raise ValueError("GSHEET_ID í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def fetch_news(rss_url, days=7, min_news=20):
    """RSS í”¼ë“œì—ì„œ ìµœê·¼ days(ê¸°ë³¸ 7ì¼) ë‚´ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê³ , published_parsedê°€ ì—†ìœ¼ë©´ published/updated ë“± ë‹¤ë¥¸ í•„ë“œë„ í™œìš©. ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ë‚ ì§œ í•„í„° ì—†ì´ ì „ì²´ ìˆ˜ì§‘."""
    feed = feedparser.parse(rss_url)
    news_list = []
    today = get_today_kst().astimezone(KST).date()
    start_date = today - timedelta(days=days-1)
    print(f"[ë””ë²„ê·¸] feed.entries ê°œìˆ˜: {len(feed.entries)}")
    filtered_count = 0
    for entry in feed.entries:
        published_date = None
        # published_parsed ìš°ì„ , ì—†ìœ¼ë©´ published/updated ë“±ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
        if hasattr(entry, 'published_parsed') and isinstance(entry.published_parsed, time.struct_time):
            published_dt = datetime.fromtimestamp(time.mktime(entry.published_parsed), tz=KST)
            published_date = published_dt.date()
        elif hasattr(entry, 'published') and isinstance(entry.published, str):
            try:
                published_dt = datetime.strptime(entry.published[:10], '%Y-%m-%d')
                published_date = published_dt.date()
            except Exception:
                published_date = None
        elif hasattr(entry, 'updated_parsed') and isinstance(entry.updated_parsed, time.struct_time):
            published_dt = datetime.fromtimestamp(time.mktime(entry.updated_parsed), tz=KST)
            published_date = published_dt.date()
        # ë””ë²„ê¹…: ì‹¤ì œ ë‚ ì§œ ê°’ ì¶œë ¥
        print(f"[ë””ë²„ê·¸] published_date: {published_date}, start_date: {start_date}, today: {today}")
        if published_date and (start_date <= published_date <= today):
            title = entry.title
            summary = entry.summary if hasattr(entry, 'summary') else ''
            published = published_date.strftime('%Y-%m-%d') if published_date else ''
            link = entry.link if hasattr(entry, 'link') else ''
            news_item = {
                'title': title,
                'summary': summary,
                'published': published,
                'link': link
            }
            news_list.append(news_item)
        else:
            filtered_count += 1
    print(f"[ë””ë²„ê·¸] ë‚ ì§œ í•„í„° í†µê³¼ ë‰´ìŠ¤: {len(news_list)}, í•„í„°ë§ëœ ë‰´ìŠ¤: {filtered_count}")
    # ë§Œì•½ ë‰´ìŠ¤ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ë‚ ì§œ í•„í„° ì—†ì´ ì „ì²´ ìˆ˜ì§‘
    if len(news_list) < min_news:
        print("[ê²½ê³ ] ë‚ ì§œ í•„í„°ë¡œ ì¶©ë¶„í•œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‚ ì§œ í•„í„° ì—†ì´ ì „ì²´ ìˆ˜ì§‘ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        news_list = []
        for entry in feed.entries:
            title = entry.title
            summary = entry.summary if hasattr(entry, 'summary') else ''
            published = ''
            if hasattr(entry, 'published_parsed') and isinstance(entry.published_parsed, time.struct_time):
                published_dt = datetime.fromtimestamp(time.mktime(entry.published_parsed), tz=KST)
                published = published_dt.strftime('%Y-%m-%d')
            elif hasattr(entry, 'published') and isinstance(entry.published, str):
                published = entry.published[:10]
            link = entry.link if hasattr(entry, 'link') else ''
            news_item = {
                'title': title,
                'summary': summary,
                'published': published,
                'link': link
            }
            news_list.append(news_item)
        print(f"[ë””ë²„ê·¸] ë‚ ì§œ ë¬´ì‹œ ì „ì²´ ìˆ˜ì§‘ ë‰´ìŠ¤: {len(news_list)}")
    return news_list

def rank_news_by_importance_with_claude(news_list):
    """Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ëª©ë¡ì„ ì¤‘ìš”ë„ì— ë”°ë¼ ìˆœìœ„ ë§¤ê¸°ê¸°"""
    client = Anthropic(api_key=CLAUDE_API_KEY)

    formatted_news = ""
    for i, news in enumerate(news_list):
        formatted_news += f"ID: {i}\nì œëª©: {news['title']}\n\n"

    prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ê¸ˆìœµ ë‰´ìŠ¤ íë ˆì´í„°ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ì˜¤ëŠ˜ê³¼ ì–´ì œ ìˆ˜ì§‘ëœ ì£¼ì‹/ì¦ê¶Œ ê´€ë ¨ ë‰´ìŠ¤ ì „ì²´ ëª©ë¡ì…ë‹ˆë‹¤.
ì´ ì¤‘ì—ì„œ 'ë…ìë“¤ì´ ë§ì´ ì½ì„ ìˆ˜ ìˆê³ , ê´€ì‹¬ì„ ê°€ì§ˆ ë§Œí•œ ë‰´ìŠ¤'ë¥¼ 20ê°œ ê³¨ë¼, ê°€ì¥ ì¤‘ìš”í•œ ìˆœì„œëŒ€ë¡œ IDë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ ì¶œë ¥í•˜ì„¸ìš”.

## ğŸŒŸ ì¤‘ìš”ë„ íŒë‹¨ ê¸°ì¤€ (ì•„ë˜ ê¸°ì¤€ + ëŒ€ì¤‘ì  ê´€ì‹¬ë„/í™”ì œì„±/ë°”ì´ëŸ´ ê°€ëŠ¥ì„±ê¹Œì§€ ê³ ë ¤)

### 1. ì‹œì¥ ì „ì²´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (ê±°ì‹œê²½ì œ, ì •ì±…)
- í†µí™”ì •ì±…(í•œêµ­ì€í–‰, Fed ê¸ˆë¦¬, ì–‘ì ì™„í™”/ê¸´ì¶•)
- ê±°ì‹œê²½ì œ ì§€í‘œ(í™˜ìœ¨ ê¸‰ë³€ë™, ìœ ê°€, ë¬¼ê°€ì§€ìˆ˜)
- ì •ë¶€ ì •ì±…/ê·œì œ(ì„¸ë²• ê°œì •, ë¶€ë™ì‚° ì •ì±…, ì‚°ì—… ê·œì œ)

### 2. íŠ¹ì • ì‚°ì—… ë° ê¸°ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
- ë°˜ë„ì²´/AI/ìë™ì°¨/2ì°¨ì „ì§€/ë°”ì´ì˜¤/í”Œë«í¼/IT ë“± í•µì‹¬ ì‚°ì—… ë™í–¥
- ì£¼ìš” ê¸°ì—… ì‹¤ì , ì‹ ì œí’ˆ, ì´ìŠˆ

### 3. íˆ¬ìì/ëŒ€ì¤‘ ê´€ì‹¬ë„
- ì™¸êµ­ì¸/ê¸°ê´€ ë™í–¥, ëŒ€ê·œëª¨ ë§¤ìˆ˜/ë§¤ë„
- ì‚¬íšŒì  ì´ìŠˆ, ë°ˆ, í™”ì œì„±, ëŒ€ì¤‘ì  ê¶ê¸ˆì¦

## ğŸ“° ë‰´ìŠ¤ ëª©ë¡
{formatted_news}

## ğŸ’» ì¶œë ¥ í˜•ì‹
- ë‹¤ë¥¸ ì„¤ëª… ì—†ì´, ê°€ì¥ ì¤‘ìš”ë„ê°€ ë†’ì€ ë‰´ìŠ¤ 20ê°œ IDë¥¼ **ì‰¼í‘œ(,)ë¡œë§Œ êµ¬ë¶„**í•˜ì—¬ í•œ ì¤„ë¡œ ì¶œë ¥
- ì˜ˆì‹œ: 5,12,3,1,8,2,7,11,0,4

ê°€ì¥ ì¤‘ìš”í•œ 20ê°œ ë‰´ìŠ¤ì˜ IDë¥¼ ìˆœì„œëŒ€ë¡œ ì‘ì„±í•˜ì„¸ìš”:
"""

    response = client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=1000,
        temperature=0.1,
        system="",
        messages=[MessageParam(role="user", content=prompt)]
    )
    response_block = response.content[0]
    response_text = getattr(response_block, 'text', None) or getattr(response_block, 'content', None) or str(response_block)
    response_text = response_text.strip()
    
    try:
        ranked_ids = [int(id_str.strip()) for id_str in response_text.split(',')]
        valid_ranked_ids = [id_val for id_val in ranked_ids if 0 <= id_val < len(news_list)]
        
        ranked_news = [news_list[i] for i in valid_ranked_ids]
        unranked_news_ids = set(range(len(news_list))) - set(valid_ranked_ids)
        unranked_news = [news_list[i] for i in unranked_news_ids]

        return ranked_news + unranked_news
    except ValueError:
        print("  ! AI ìˆœìœ„ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨. ì›ë˜ ìˆœì„œëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return news_list

def create_parody_with_claude(news_content, original_prompt, existing_titles, retry_context=None):
    """Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ íŒ¨ëŸ¬ë”” ìƒì„± (ì¤‘ë³µ ë°©ì§€ ë° ìë™ ë³µêµ¬ ê¸°ëŠ¥ í¬í•¨)"""
    client = Anthropic(api_key=CLAUDE_API_KEY)
    
    # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    if existing_titles:
        # f-string í‘œí˜„ì‹ì—ì„œ ë°±ìŠ¬ë˜ì‹œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ìˆ˜ì •
        title_list_str = "\n- ".join(existing_titles)
        duplication_warning = (
            "\n\n## âœï¸ (ë§¤ìš° ì¤‘ìš”) ì¤‘ë³µ íŒ¨ëŸ¬ë”” ë°©ì§€\n"
            "- ì•„ë˜ëŠ” ì´ë¯¸ ìƒì„±ëœ íŒ¨ëŸ¬ë”” ì œëª©ë“¤ì…ë‹ˆë‹¤.\n"
            "- ì ˆëŒ€ë¡œ ì•„ë˜ ëª©ë¡ê³¼ ìœ ì‚¬í•œ ë‚´ìš©ì´ë‚˜ ìŠ¤íƒ€ì¼ì˜ `parody_title`ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.\n"
            "- ì™„ì „íˆ ìƒˆë¡­ê³ , ì°½ì˜ì ì¸ ì œëª©ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.\n\n"
            "### ğŸ“œ ì´ë¯¸ ìƒì„±ëœ ì œëª© ëª©ë¡:\n"
            f"- {title_list_str}"
        )
        original_prompt += duplication_warning

    messages = [MessageParam(role="user", content=original_prompt)]
    
    if retry_context:
        user_message = f"""ì´ì „ ì‘ë‹µì— ì˜¤ë¥˜ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
## ì´ì „ ì‘ë‹µ (ì˜ëª»ëœ ë¶€ë¶„)
{retry_context['malformed_json']}
## ë°œìƒí•œ ì˜¤ë¥˜
{retry_context['error_message']}
ìœ„ ì˜¤ë¥˜ë¥¼ ì°¸ê³ í•˜ì—¬, ìœ íš¨í•œ JSON í˜•ì‹ì— ë§ì¶° ìˆ˜ì •ëœ ì‘ë‹µì„ ```json ... ``` ì½”ë“œ ë¸”ë¡ ì•ˆì— ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
        messages.append(MessageParam(role="assistant", content=retry_context['malformed_json']))
        messages.append(MessageParam(role="user", content=user_message))

    response = client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=2000,
        temperature=0.7,
        system="",
        messages=messages
    )
    
    return response.content

def save_to_gsheet(parody_data_list):
    """íŒ¨ëŸ¬ë”” ë°ì´í„°ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ (ì‹œíŠ¸ ì´ˆê¸°í™” í›„ ì €ì¥)"""
    sheet = get_gsheet(SHEET_ID, 'today_stock_parody')
    
    # ì‹œíŠ¸ ì´ˆê¸°í™”
    sheet.clear()
    
    # í—¤ë” ì¶”ê°€
    headers = [
        'date', 'original_title', 'parody_title', 'setup', 
        'punchline', 'humor_lesson', 'disclaimer', 'source_url'
    ]
    sheet.append_row(headers)
    
    # ë°ì´í„° ì¶”ê°€
    for parody_data in parody_data_list:
        row = [
            parody_data.get('date', ''),
            parody_data.get('original_title', ''),
            parody_data.get('parody_title', ''),
            parody_data.get('setup', ''),
            parody_data.get('punchline', ''),
            parody_data.get('humor_lesson', ''),
            parody_data.get('disclaimer', ''),
            parody_data.get('source_url', '')
        ]
        sheet.append_row(row)

def main():
    print("[1/5] í•œê²½ ì¦ê¶Œë‰´ìŠ¤ë§Œ ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ë‰´ìŠ¤ ì„ ë³„ ì¤‘...")
    raw_config = parse_rawdata()
    if not raw_config:
        print("[ì˜¤ë¥˜] ì„¤ì • íŒŒì¼(asset/rawdata.txt)ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    rss_urls = raw_config.get('RSS_URL ì§€ì •', [])
    if isinstance(rss_urls, str):
        rss_urls = [rss_urls]
    if not rss_urls:
        print("[ì˜¤ë¥˜] asset/rawdata.txt íŒŒì¼ì—ì„œ 'RSS_URL ì§€ì •'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    rss_url = rss_urls[0]  # í•œê²½ ì¦ê¶Œë‰´ìŠ¤ë§Œ ì‚¬ìš©
    all_news = fetch_news(rss_url)
    if not all_news:
        print("\n[ì˜¤ë¥˜] í•œê²½ ì¦ê¶Œë‰´ìŠ¤ì—ì„œ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    print(f"\n[2/5] Claude 3.5ê°€ ë…ìë“¤ì´ ê°€ì¥ ê´€ì‹¬ì„ ê°€ì§ˆ ë§Œí•œ ë‰´ìŠ¤ 20ê°œë¥¼ ì§ì ‘ ì„ ì •í•©ë‹ˆë‹¤...")
    ranked_news = rank_news_by_importance_with_claude(all_news)
    top_news = ranked_news[:20]
    print(f"\n[2.5/5] ì´ {len(top_news)}ê°œ ë‰´ìŠ¤ ì„ ë³„ ì™„ë£Œ! íŒ¨ëŸ¬ë”” ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print(f"\n[3/5] ì¤‘ìš”ë„ ìƒìœ„ {len(top_news)}ê°œ ë‰´ìŠ¤ë¡œ íŒ¨ëŸ¬ë”” ìƒì„± ì¤‘...")
    parody_data_list = []
    today_str = get_today_kst().strftime('%Y-%m-%d')
    existing_parody_titles = []
    for i, news in enumerate(top_news):
        news_content = f"ì œëª©: {news['title']}\në‚´ìš©: {news['summary']}\në§í¬: {news['link']}"
        current_date = today_str
        original_title_safe = news['title'].replace('"', "'")
        news_link = news['link']
        news_title = news['title']
        news_summary = news['summary']
        parody_prompt = f"""
ë‹¹ì‹ ì€ ì¡°íšŒìˆ˜ ê¸‰ìƒìŠ¹ì„ ëª©í‘œë¡œ í•˜ëŠ” ì¦ê¶Œ ë‰´ìŠ¤ íŒ¨ëŸ¬ë”” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ã€í•µì‹¬ ë¯¸ì…˜ã€‘
- 30-50ëŒ€ ì§ì¥ì¸ íƒ€ê²Ÿ
- 90ì´ˆ ì´ë‚´ ìˆí¼ ì½˜í…ì¸ 
- ì•„ì¹¨ ì¶œê·¼ê¸¸ ìµœì í™”
- ë°”ì´ëŸ´ ìš”ì†Œ ê·¹ëŒ€í™”

ã€ì œëª© ì‘ì„±ë²•ã€‘
- 20ì ì´ë‚´, ì¶©ê²© ìˆ«ì/ê°ì •/ê°œë¯¸ ê´€ì /ê¶ê¸ˆì¦ ìœ ë°œ í¬í•¨
- ë‚ ì§œ, 'AIê°€ ë¶„ì„í•œ', ì¿ íŒ¡íŒŒíŠ¸ë„ˆìŠ¤ ë©˜ì…˜ ë“±ì€ ì ˆëŒ€ ê¸ˆì§€

ã€ì¹´ë“œë‰´ìŠ¤ êµ¬ì¡°ã€‘
- parody_title: 20ì ì´ë‚´, í´ë¦­ì„ ë¶€ë¥´ëŠ” í‚¬ë§ íƒ€ì´í‹€ (ì˜ˆ: 'ì—”ë¹„ë””ì•„ 4ì¡°ë‹¬ëŸ¬! ê°œë¯¸ ì§‘ë‹¨ì‹¤ì‹ ')
- setup: í˜„ì‹¤ íƒ€ê²©, ê°œë¯¸ ê´€ì , íšŒì‚¬ ê°œê·¸, ê³µê°ëŒ€, í¬ë§ ë©”ì‹œì§€, AI ì¦ì‹œ ê²©ì–¸, í•´ì‹œíƒœê·¸ ì „ëµ ë“±ì—ì„œ ê°€ì¥ ì„íŒ©íŠ¸ ìˆëŠ” í•œ ì¤„
- punchline: ìœ„íŠ¸/ë°˜ì „/ì¬ì¹˜/íšŒì‚¬ ëŒ€í™”/ë°ˆ/ì´ëª¨ì§€ ë“± í™œìš©, 35ì ì´ë‚´
- humor_lesson: íˆ¬ììì—ê²Œ ì‹¤ì§ˆì  ì¡°ì–¸ ë˜ëŠ” ëª…ì–¸, AI ê²©ì–¸, ê¸ì •ì  ë©”ì‹œì§€
- disclaimer: 'ë©´ì±…ì¡°í•­:íŒ¨ëŸ¬ë””/íŠ¹ì •ê¸°ê´€,ê°œì¸ê³¼ ë¬´ê´€/íˆ¬ìì¡°ì–¸ì•„ë‹˜/ì¬ë¯¸ëª©ì '
- source_url: ì›ë³¸ ë‰´ìŠ¤ ë§í¬

ã€ì¶œë ¥ ì˜ˆì‹œã€‘
```json
{{
  "date": "{current_date}",
  "original_title": "{original_title_safe}",
  "parody_title": "ì—”ë¹„ë””ì•„ 4ì¡°ë‹¬ëŸ¬! ê°œë¯¸ ì§‘ë‹¨ì‹¤ì‹ ",
  "setup": "ê°œë¯¸ë“¤, ì˜¤ëŠ˜ë„ ì›”ê¸‰ì€ ê·¸ëŒ€ë¡œì¸ë° ì£¼ê°€ëŠ” ë˜ ì˜¬ëë‹¤.",
  "punchline": "ë™ë£Œ: 'ì—”ë¹„ë””ì•„ ì–´ë•Œ?' ë‚˜: '4ì¡° ë‹¬ëŸ¬ ëŒíŒŒ!' ë™ë£Œ: 'ìš°ë¦¬ íšŒì‚¬ë„ 4ì¡°... ì ì!'",
  "humor_lesson": "ì£¼ê°€ëŠ” ê³„ë‹¨ìœ¼ë¡œ ì˜¤ë¥´ê³  ì°½ë¬¸ìœ¼ë¡œ ë–¨ì–´ì§„ë‹¤.",
  "disclaimer": "ë©´ì±…ì¡°í•­:íŒ¨ëŸ¬ë””/íŠ¹ì •ê¸°ê´€,ê°œì¸ê³¼ ë¬´ê´€/íˆ¬ìì¡°ì–¸ì•„ë‹˜/ì¬ë¯¸ëª©ì ",
  "source_url": "{news_link}"
}}
```

ã€ì ˆëŒ€ ê·œì¹™ã€‘
- ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë¡œë§Œ ì¶œë ¥
- ê° í•„ë“œëŠ” string
- ì´ëª¨ì§€(emoji)ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ (ì–´ë–¤ í•„ë“œì—ë„ ì´ëª¨ì§€ ê¸ˆì§€)
- ëŒ€ì‹  !!!, ???, ~~~, ... ë“± ì•„ë‚ ë¡œê·¸ ë°©ì‹ì˜ ê°•ì¡°(êµ¬ë‘ì , ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ, ë¬¼ê²° ë“±)ëŠ” ì ê·¹ì ìœ¼ë¡œ í™œìš©í•  ê²ƒ
- ë°ˆ, íšŒì‚¬ê°œê·¸, AIê²©ì–¸, í•´ì‹œíƒœê·¸ ì „ëµì€ setup/punchline/humor_lessonì— ì ê·¹ ë°˜ì˜
- ë‚ ì§œ/AI/ì¿ íŒ¡íŒŒíŠ¸ë„ˆìŠ¤ ë©˜ì…˜ì€ parody_titleì— ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ ê²ƒ

ì•„ë˜ëŠ” ì…ë ¥ ë‰´ìŠ¤ì…ë‹ˆë‹¤.
- ì œëª©: {news_title}
- ìš”ì•½: {news_summary}
- ë§í¬: {news_link}

ã€ì¶œë ¥ ì ˆëŒ€ ê·œì¹™ã€‘
- ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë¡œë§Œ ì¶œë ¥(ì„¤ëª…, í•´ì„¤, ì—¬ëŠ” ë§, ë‹«ëŠ” ë§ ì—†ì´)
- ëª¨ë“  í•„ë“œëŠ” string, ë¹ˆ ê°’ ì—†ì´ 1~2ë¬¸ì¥ ì´ë‚´ë¡œ ì±„ìš¸ ê²ƒ
- ê° í•„ë“œì— ì´ëª¨ì§€(emoji)ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
- ëŒ€ì‹  !!!, ???, ~~~, ... ë“± ì•„ë‚ ë¡œê·¸ ê°•ì¡°ëŠ” ì ê·¹ í™œìš©
- í•´ì‹œíƒœê·¸ëŠ” humor_lessonì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- ì¶œë ¥ ì˜ˆì‹œì™€ ì™„ì „íˆ ë™ì¼í•œ êµ¬ì¡°, í•„ë“œëª…, ìˆœì„œë¡œë§Œ ì¶œë ¥

ìœ„ êµ¬ì¡°ì™€ ì§€ì¹¨ì„ ì—„ê²©íˆ ë”°ë¼, ì…ë ¥ ë‰´ìŠ¤(ì œëª©/ìš”ì•½/ë§í¬)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹´ë“œë‰´ìŠ¤ íŒ¨ëŸ¬ë”” ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ë¼.
"""
        print(f"  - [{i+1}/{len(top_news)}] íŒ¨ëŸ¬ë”” ìƒì„± ì¤‘...")
        response_text = ""
        error = None
        for attempt in range(2):
            try:
                retry_context = None
                if attempt > 0:
                    retry_context = {"malformed_json": response_text, "error_message": str(error)}
                parody_result_blocks = create_parody_with_claude(
                    news_content, parody_prompt, existing_parody_titles, retry_context
                )
                response_block = parody_result_blocks[0]
                response_text = getattr(response_block, 'text', None) or getattr(response_block, 'content', None) or str(response_block)
                json_match = re.search(r'```json\n(\{.*?\})\n```', response_text, re.DOTALL)
                if not json_match:
                    start_index = response_text.find('{')
                    end_index = response_text.rfind('}')
                    if start_index != -1 and end_index != -1 and start_index < end_index:
                        json_text = response_text[start_index:end_index+1]
                    else:
                        json_text = response_text
                else:
                    json_text = json_match.group(1)
                parody_data = json.loads(json_text)
                parody_data_list.append(parody_data)
                existing_parody_titles.append(parody_data['parody_title'])
                print("    - ì„±ê³µ!")
                break
            except Exception as e:
                error = e
                print(f"    ! íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/2)")
                if attempt == 1:
                    print(f"    - ìµœì¢… ì‹¤íŒ¨: {e}")
    if not parody_data_list:
        print("\n[ì˜¤ë¥˜] íŒ¨ëŸ¬ë”” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    print(f"\n[4/5] ì´ {len(parody_data_list)}ê°œ íŒ¨ëŸ¬ë”” ìƒì„± ì™„ë£Œ! êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤.")
    save_to_gsheet(parody_data_list)
    print(f"\n[5/5] êµ¬ê¸€ ì‹œíŠ¸ì— íŒ¨ëŸ¬ë”” ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()